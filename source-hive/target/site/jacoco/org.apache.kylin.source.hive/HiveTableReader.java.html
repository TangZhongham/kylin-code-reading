<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="zh"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>HiveTableReader.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache Kylin - Hive Source</a> &gt; <a href="index.source.html" class="el_package">org.apache.kylin.source.hive</a> &gt; <span class="el_source">HiveTableReader.java</span></div><h1>HiveTableReader.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
*/

package org.apache.kylin.source.hive;

import java.io.IOException;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.hadoop.hive.conf.HiveConf;
import org.apache.hive.hcatalog.common.HCatException;
import org.apache.hive.hcatalog.data.HCatRecord;
import org.apache.hive.hcatalog.data.transfer.DataTransferFactory;
import org.apache.hive.hcatalog.data.transfer.HCatReader;
import org.apache.hive.hcatalog.data.transfer.ReadEntity;
import org.apache.hive.hcatalog.data.transfer.ReaderContext;
import org.apache.kylin.source.IReadableTable.TableReader;

/**
 * An implementation of TableReader with HCatalog for Hive table.
 */
public class HiveTableReader implements TableReader {

    private String dbName;
    private String tableName;
<span class="nc" id="L45">    private int currentSplit = -1;</span>
<span class="nc" id="L46">    private ReaderContext readCntxt = null;</span>
<span class="nc" id="L47">    private Iterator&lt;HCatRecord&gt; currentHCatRecordItr = null;</span>
    private HCatRecord currentHCatRecord;
<span class="nc" id="L49">    private int numberOfSplits = 0;</span>
<span class="nc" id="L50">    private Map&lt;String, String&gt; partitionKV = null;</span>

    /**
     * Constructor for reading whole hive table
     * @param dbName
     * @param tableName
     * @throws IOException
     */
    public HiveTableReader(String dbName, String tableName) throws IOException {
<span class="nc" id="L59">        this(dbName, tableName, null);</span>
<span class="nc" id="L60">    }</span>

    /**
     * Constructor for reading a partition of the hive table
     * @param dbName
     * @param tableName
     * @param partitionKV key-value pairs condition on the partition
     * @throws IOException
     */
<span class="nc" id="L69">    public HiveTableReader(String dbName, String tableName, Map&lt;String, String&gt; partitionKV) throws IOException {</span>
<span class="nc" id="L70">        this.dbName = dbName;</span>
<span class="nc" id="L71">        this.tableName = tableName;</span>
<span class="nc" id="L72">        this.partitionKV = partitionKV;</span>
<span class="nc" id="L73">        initialize();</span>
<span class="nc" id="L74">    }</span>

    private void initialize() throws IOException {
        try {
<span class="nc" id="L78">            this.readCntxt = getHiveReaderContext(dbName, tableName, partitionKV);</span>
<span class="nc" id="L79">        } catch (Exception e) {</span>
<span class="nc" id="L80">            e.printStackTrace();</span>
<span class="nc" id="L81">            throw new IOException(e);</span>
<span class="nc" id="L82">        }</span>

<span class="nc" id="L84">        this.numberOfSplits = readCntxt.numSplits();</span>
<span class="nc" id="L85">    }</span>

    @Override
    public boolean next() throws IOException {

<span class="nc bnc" id="L90" title="All 4 branches missed.">        while (currentHCatRecordItr == null || !currentHCatRecordItr.hasNext()) {</span>
<span class="nc" id="L91">            currentSplit++;</span>
<span class="nc bnc" id="L92" title="All 2 branches missed.">            if (currentSplit == numberOfSplits) {</span>
<span class="nc" id="L93">                return false;</span>
            }

<span class="nc" id="L96">            currentHCatRecordItr = loadHCatRecordItr(readCntxt, currentSplit);</span>
        }

<span class="nc" id="L99">        currentHCatRecord = currentHCatRecordItr.next();</span>

<span class="nc" id="L101">        return true;</span>
    }

    @Override
    public String[] getRow() {
<span class="nc" id="L106">        return getRowAsStringArray(currentHCatRecord);</span>
    }

    public List&lt;String&gt; getRowAsList() {
<span class="nc" id="L110">        return getRowAsList(currentHCatRecord);</span>
    }

    public static List&lt;String&gt; getRowAsList(HCatRecord record, List&lt;String&gt; rowValues) {
<span class="nc" id="L114">        List&lt;Object&gt; allFields = record.getAll();</span>
<span class="nc bnc" id="L115" title="All 2 branches missed.">        for (Object o : allFields) {</span>
<span class="nc bnc" id="L116" title="All 2 branches missed.">            rowValues.add((o == null) ? null : o.toString());</span>
<span class="nc" id="L117">        }</span>
<span class="nc" id="L118">        return rowValues;</span>
    }

    public static List&lt;String&gt; getRowAsList(HCatRecord record) {
<span class="nc" id="L122">        return Arrays.asList(getRowAsStringArray(record));</span>
    }

    public static String[] getRowAsStringArray(HCatRecord record) {
<span class="nc" id="L126">        String[] arr = new String[record.size()];</span>
<span class="nc bnc" id="L127" title="All 2 branches missed.">        for (int i = 0; i &lt; arr.length; i++) {</span>
<span class="nc" id="L128">            Object o = record.get(i);</span>
<span class="nc bnc" id="L129" title="All 4 branches missed.">            arr[i] = (o == null || &quot;\\N&quot;.equals(o)) ? null : o.toString();</span>
        }
<span class="nc" id="L131">        return arr;</span>
    }

    @Override
    public void close() throws IOException {
<span class="nc" id="L136">        this.readCntxt = null;</span>
<span class="nc" id="L137">        this.currentHCatRecordItr = null;</span>
<span class="nc" id="L138">        this.currentHCatRecord = null;</span>
<span class="nc" id="L139">        this.currentSplit = -1;</span>
<span class="nc" id="L140">    }</span>

    public String toString() {
<span class="nc" id="L143">        return &quot;hive table reader for: &quot; + dbName + &quot;.&quot; + tableName;</span>
    }

    private static ReaderContext getHiveReaderContext(String database, String table, Map&lt;String, String&gt; partitionKV) throws Exception {
<span class="nc" id="L147">        HiveConf hiveConf = new HiveConf(HiveTableReader.class);</span>
<span class="nc" id="L148">        Iterator&lt;Entry&lt;String, String&gt;&gt; itr = hiveConf.iterator();</span>
<span class="nc" id="L149">        Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();</span>
<span class="nc bnc" id="L150" title="All 2 branches missed.">        while (itr.hasNext()) {</span>
<span class="nc" id="L151">            Entry&lt;String, String&gt; kv = itr.next();</span>
<span class="nc" id="L152">            map.put(kv.getKey(), kv.getValue());</span>
<span class="nc" id="L153">        }</span>

        ReadEntity entity;
<span class="nc bnc" id="L156" title="All 4 branches missed.">        if (partitionKV == null || partitionKV.size() == 0) {</span>
<span class="nc" id="L157">            entity = new ReadEntity.Builder().withDatabase(database).withTable(table).build();</span>
        } else {
<span class="nc" id="L159">            entity = new ReadEntity.Builder().withDatabase(database).withTable(table).withPartition(partitionKV).build();</span>
        }

<span class="nc" id="L162">        HCatReader reader = DataTransferFactory.getHCatReader(entity, map);</span>
<span class="nc" id="L163">        ReaderContext cntxt = reader.prepareRead();</span>

<span class="nc" id="L165">        return cntxt;</span>
    }

    private static Iterator&lt;HCatRecord&gt; loadHCatRecordItr(ReaderContext readCntxt, int dataSplit) throws HCatException {
<span class="nc" id="L169">        HCatReader currentHCatReader = DataTransferFactory.getHCatReader(readCntxt, dataSplit);</span>

<span class="nc" id="L171">        return currentHCatReader.read();</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>