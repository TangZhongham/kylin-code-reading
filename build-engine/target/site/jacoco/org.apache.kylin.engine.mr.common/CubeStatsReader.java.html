<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="zh"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>CubeStatsReader.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache Kylin - Build Engine</a> &gt; <a href="index.source.html" class="el_package">org.apache.kylin.engine.mr.common</a> &gt; <span class="el_source">CubeStatsReader.java</span></div><h1>CubeStatsReader.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
*/

package org.apache.kylin.engine.mr.common;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStreamWriter;
import java.io.PrintWriter;
import java.nio.charset.StandardCharsets;
import java.text.DecimalFormat;
import java.text.DecimalFormatSymbols;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Locale;
import java.util.Map;

import org.apache.commons.lang.StringUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.io.SequenceFile.Reader;
import org.apache.hadoop.io.SequenceFile.Reader.Option;
import org.apache.hadoop.util.ReflectionUtils;
import org.apache.kylin.common.KylinConfig;
import org.apache.kylin.common.persistence.RawResource;
import org.apache.kylin.common.persistence.ResourceStore;
import org.apache.kylin.common.util.ByteArray;
import org.apache.kylin.common.util.Bytes;
import org.apache.kylin.common.util.HadoopUtil;
import org.apache.kylin.common.util.SumHelper;
import org.apache.kylin.cube.CubeInstance;
import org.apache.kylin.cube.CubeManager;
import org.apache.kylin.cube.CubeSegment;
import org.apache.kylin.cube.cuboid.Cuboid;
import org.apache.kylin.cube.cuboid.CuboidScheduler;
import org.apache.kylin.cube.kv.RowKeyEncoder;
import org.apache.kylin.cube.model.CubeDesc;
import org.apache.kylin.measure.hllc.HLLCounter;
import org.apache.kylin.measure.topn.TopNMeasureType;
import org.apache.kylin.metadata.datatype.DataType;
import org.apache.kylin.metadata.model.FunctionDesc;
import org.apache.kylin.metadata.model.MeasureDesc;
import org.apache.kylin.metadata.model.SegmentStatusEnum;
import org.apache.kylin.metadata.model.TblColRef;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.Lists;
import com.google.common.collect.Maps;

/**
 * This should be in cube module. It's here in engine-mr because currently stats
 * are saved as sequence files thus a hadoop dependency.
 */
public class CubeStatsReader {

<span class="nc" id="L80">    private static final Logger logger = LoggerFactory.getLogger(CubeStatsReader.class);</span>

    final CubeSegment seg;
    final int samplingPercentage;
    final int mapperNumberOfFirstBuild; // becomes meaningless after merge
    final double mapperOverlapRatioOfFirstBuild; // becomes meaningless after merge
    final Map&lt;Long, HLLCounter&gt; cuboidRowEstimatesHLL;
    final CuboidScheduler cuboidScheduler;
    public final long sourceRowCount;

    public CubeStatsReader(CubeSegment cubeSegment, KylinConfig kylinConfig) throws IOException {
<span class="nc" id="L91">        this(cubeSegment, cubeSegment.getCuboidScheduler(), kylinConfig);</span>
<span class="nc" id="L92">    }</span>

    /**
     * @param cuboidScheduler if it's null, part of it's functions will not be supported
     */
    public CubeStatsReader(CubeSegment cubeSegment, CuboidScheduler cuboidScheduler, KylinConfig kylinConfig)
<span class="nc" id="L98">            throws IOException {</span>
<span class="nc" id="L99">        this.seg = cubeSegment;</span>
<span class="nc" id="L100">        this.cuboidScheduler = cuboidScheduler;</span>
<span class="nc" id="L101">        ResourceStore store = ResourceStore.getStore(kylinConfig);</span>
<span class="nc" id="L102">        String statsKey = cubeSegment.getStatisticsResourcePath();</span>
<span class="nc" id="L103">        RawResource resource = store.getResource(statsKey);</span>
<span class="nc bnc" id="L104" title="All 2 branches missed.">        if (resource != null) {</span>
<span class="nc" id="L105">            File tmpSeqFile = writeTmpSeqFile(resource.content());</span>
<span class="nc" id="L106">            Path path = new Path(HadoopUtil.fixWindowsPath(&quot;file://&quot; + tmpSeqFile.getAbsolutePath()));</span>
<span class="nc" id="L107">            logger.info(&quot;Reading statistics from {}&quot;, path);</span>
<span class="nc" id="L108">            CubeStatsResult cubeStatsResult = new CubeStatsResult(path, kylinConfig.getCubeStatsHLLPrecision());</span>
<span class="nc" id="L109">            tmpSeqFile.delete();</span>

<span class="nc" id="L111">            this.samplingPercentage = cubeStatsResult.getPercentage();</span>
<span class="nc" id="L112">            this.mapperNumberOfFirstBuild = cubeStatsResult.getMapperNumber();</span>
<span class="nc" id="L113">            this.mapperOverlapRatioOfFirstBuild = cubeStatsResult.getMapperOverlapRatio();</span>
<span class="nc" id="L114">            this.cuboidRowEstimatesHLL = cubeStatsResult.getCounterMap();</span>
<span class="nc" id="L115">            this.sourceRowCount = cubeStatsResult.getSourceRecordCount();</span>
<span class="nc" id="L116">        } else {</span>
            // throw new IllegalStateException(&quot;Missing resource at &quot; + statsKey);
<span class="nc" id="L118">            logger.warn(&quot;{} is not exists.&quot;, statsKey);</span>
<span class="nc" id="L119">            this.samplingPercentage = -1;</span>
<span class="nc" id="L120">            this.mapperNumberOfFirstBuild = -1;</span>
<span class="nc" id="L121">            this.mapperOverlapRatioOfFirstBuild = -1.0;</span>
<span class="nc" id="L122">            this.cuboidRowEstimatesHLL = null;</span>
<span class="nc" id="L123">            this.sourceRowCount = -1L;</span>
        }
<span class="nc" id="L125">    }</span>

    /**
     * Read statistics from
     * @param path
     * rather than
     * @param cubeSegment
     *
     * Since the statistics are from
     * @param path
     * cuboid scheduler should be provided by default
     */
    public CubeStatsReader(CubeSegment cubeSegment, CuboidScheduler cuboidScheduler, KylinConfig kylinConfig, Path path)
<span class="nc" id="L138">            throws IOException {</span>
<span class="nc" id="L139">        CubeStatsResult cubeStatsResult = new CubeStatsResult(path, kylinConfig.getCubeStatsHLLPrecision());</span>

<span class="nc" id="L141">        this.seg = cubeSegment;</span>
<span class="nc" id="L142">        this.cuboidScheduler = cuboidScheduler;</span>
<span class="nc" id="L143">        this.samplingPercentage = cubeStatsResult.getPercentage();</span>
<span class="nc" id="L144">        this.mapperNumberOfFirstBuild = cubeStatsResult.getMapperNumber();</span>
<span class="nc" id="L145">        this.mapperOverlapRatioOfFirstBuild = cubeStatsResult.getMapperOverlapRatio();</span>
<span class="nc" id="L146">        this.cuboidRowEstimatesHLL = cubeStatsResult.getCounterMap();</span>
<span class="nc" id="L147">        this.sourceRowCount = cubeStatsResult.getSourceRecordCount();</span>
<span class="nc" id="L148">    }</span>

    private File writeTmpSeqFile(InputStream inputStream) throws IOException {
<span class="nc" id="L151">        File tempFile = File.createTempFile(&quot;kylin_stats_tmp&quot;, &quot;.seq&quot;);</span>
<span class="nc" id="L152">        FileOutputStream out = null;</span>
        try {
<span class="nc" id="L154">            out = new FileOutputStream(tempFile);</span>
<span class="nc" id="L155">            org.apache.commons.io.IOUtils.copy(inputStream, out);</span>
        } finally {
<span class="nc" id="L157">            IOUtils.closeStream(inputStream);</span>
<span class="nc" id="L158">            IOUtils.closeStream(out);</span>
        }
<span class="nc" id="L160">        return tempFile;</span>
    }

    public Map&lt;Long, HLLCounter&gt; getCuboidRowHLLCounters() {
<span class="nc" id="L164">        return this.cuboidRowEstimatesHLL;</span>
    }

    public int getSamplingPercentage() {
<span class="nc" id="L168">        return samplingPercentage;</span>
    }

    public long getSourceRowCount() {
<span class="nc" id="L172">        return sourceRowCount;</span>
    }

    public Map&lt;Long, Long&gt; getCuboidRowEstimatesHLL() {
<span class="nc bnc" id="L176" title="All 2 branches missed.">        if (cuboidRowEstimatesHLL == null) {</span>
<span class="nc" id="L177">            return null;</span>
        }
<span class="nc" id="L179">        return getCuboidRowCountMapFromSampling(cuboidRowEstimatesHLL, samplingPercentage);</span>
    }

    public Map&lt;Long, Double&gt; getCuboidSizeMap() {
<span class="nc" id="L183">        return getCuboidSizeMap(false);</span>
    }

    public Map&lt;Long, Double&gt; getCuboidSizeMap(boolean origin) {
<span class="nc" id="L187">        return getCuboidSizeMapFromRowCount(seg, getCuboidRowEstimatesHLL(), sourceRowCount, origin);</span>
    }

    public double estimateCubeSize() {
<span class="nc" id="L191">        return SumHelper.sumDouble(getCuboidSizeMap().values());</span>
    }

    public int getMapperNumberOfFirstBuild() {
<span class="nc" id="L195">        return mapperNumberOfFirstBuild;</span>
    }

    public double getMapperOverlapRatioOfFirstBuild() {
<span class="nc" id="L199">        return mapperOverlapRatioOfFirstBuild;</span>
    }

    public static Map&lt;Long, Long&gt; getCuboidRowCountMapFromSampling(Map&lt;Long, HLLCounter&gt; hllcMap,
            int samplingPercentage) {
<span class="nc" id="L204">        Map&lt;Long, Long&gt; cuboidRowCountMap = Maps.newHashMap();</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">        for (Map.Entry&lt;Long, HLLCounter&gt; entry : hllcMap.entrySet()) {</span>
            // No need to adjust according sampling percentage. Assumption is that data set is far
            // more than cardinality. Even a percentage of the data should already see all cardinalities.
<span class="nc" id="L208">            cuboidRowCountMap.put(entry.getKey(), entry.getValue().getCountEstimate());</span>
<span class="nc" id="L209">        }</span>
<span class="nc" id="L210">        return cuboidRowCountMap;</span>
    }

    public static Map&lt;Long, Double&gt; getCuboidSizeMapFromRowCount(CubeSegment cubeSegment, Map&lt;Long, Long&gt; rowCountMap,
            long sourceRowCount) {
<span class="nc" id="L215">        return getCuboidSizeMapFromRowCount(cubeSegment, rowCountMap, sourceRowCount, true);</span>
    }

    private static Map&lt;Long, Double&gt; getCuboidSizeMapFromRowCount(CubeSegment cubeSegment, Map&lt;Long, Long&gt; rowCountMap,
                                                                  long sourceRowCount, boolean origin) {
<span class="nc" id="L220">        final CubeDesc cubeDesc = cubeSegment.getCubeDesc();</span>
<span class="nc" id="L221">        final List&lt;Integer&gt; rowkeyColumnSize = Lists.newArrayList();</span>
<span class="nc" id="L222">        final Cuboid baseCuboid = Cuboid.getBaseCuboid(cubeDesc);</span>
<span class="nc" id="L223">        final List&lt;TblColRef&gt; columnList = baseCuboid.getColumns();</span>
<span class="nc" id="L224">        final Long baseCuboidRowCount = rowCountMap.get(baseCuboid.getId());</span>

<span class="nc bnc" id="L226" title="All 2 branches missed.">        for (int i = 0; i &lt; columnList.size(); i++) {</span>
            /*
             * A workaround, for the fact kylin do not support self-defined encode in Kylin 4,
             * it is done by Parquet(https://github.com/apache/parquet-format/blob/master/Encodings.md) for Kylin 4.
             * It's complex and hard to calculate real size for specific literal value, so I propose to use 4 for a rough estimation.
             */
<span class="nc" id="L232">            rowkeyColumnSize.add(4);</span>
        }

<span class="nc" id="L235">        Map&lt;Long, Double&gt; sizeMap = Maps.newHashMap();</span>
<span class="nc bnc" id="L236" title="All 2 branches missed.">        for (Map.Entry&lt;Long, Long&gt; entry : rowCountMap.entrySet()) {</span>
<span class="nc" id="L237">            sizeMap.put(entry.getKey(), estimateCuboidStorageSize(cubeSegment, entry.getKey(), entry.getValue(),</span>
<span class="nc" id="L238">                    baseCuboid.getId(), baseCuboidRowCount, rowkeyColumnSize, sourceRowCount));</span>
<span class="nc" id="L239">        }</span>

<span class="nc bnc" id="L241" title="All 4 branches missed.">        if (!origin &amp;&amp; cubeSegment.getConfig().enableJobCuboidSizeOptimize()) {</span>
<span class="nc" id="L242">            optimizeSizeMap(sizeMap, cubeSegment);</span>
        }

<span class="nc" id="L245">        return sizeMap;</span>
    }

    private static Double harmonicMean(List&lt;Double&gt; data) {
<span class="nc bnc" id="L249" title="All 4 branches missed.">        if (data == null || data.size() == 0) {</span>
<span class="nc" id="L250">            return 1.0;</span>
        }
<span class="nc" id="L252">        Double sum = 0.0;</span>
<span class="nc bnc" id="L253" title="All 2 branches missed.">        for (Double item : data) {</span>
<span class="nc" id="L254">            sum += 1.0 / item;</span>
<span class="nc" id="L255">        }</span>
<span class="nc" id="L256">        return data.size() / sum;</span>
    }

    private static List&lt;Double&gt; getHistoricalRating(CubeSegment cubeSegment,
                                                    CubeInstance cubeInstance,
                                                    int totalLevels) {
<span class="nc" id="L262">        boolean isMerged = cubeSegment.isMerged();</span>

<span class="nc" id="L264">        Map&lt;Integer, List&lt;Double&gt;&gt; layerRatio = Maps.newHashMap();</span>
<span class="nc" id="L265">        List&lt;Double&gt; result = Lists.newArrayList();</span>

<span class="nc bnc" id="L267" title="All 2 branches missed.">        for (CubeSegment seg : cubeInstance.getSegments(SegmentStatusEnum.READY)) {</span>
<span class="nc bnc" id="L268" title="All 4 branches missed.">            if (seg.isMerged() != isMerged || seg.getEstimateRatio() == null) {</span>
<span class="nc" id="L269">                continue;</span>
            }

<span class="nc" id="L272">            logger.info(&quot;get ratio from {} with: {}&quot;, seg.getName(), StringUtils.join(seg.getEstimateRatio(), &quot;,&quot;));</span>

<span class="nc bnc" id="L274" title="All 2 branches missed.">            for(int level = 0; level &lt;= totalLevels; level++) {</span>
<span class="nc bnc" id="L275" title="All 2 branches missed.">                if (seg.getEstimateRatio().get(level) &lt;= 0) {</span>
<span class="nc" id="L276">                    continue;</span>
                }

<span class="nc bnc" id="L279" title="All 2 branches missed.">                List&lt;Double&gt; temp = layerRatio.get(level) == null ? Lists.newArrayList() : layerRatio.get(level);</span>

<span class="nc" id="L281">                temp.add(seg.getEstimateRatio().get(level));</span>
<span class="nc" id="L282">                layerRatio.put(level, temp);</span>
            }
<span class="nc" id="L284">        }</span>

<span class="nc bnc" id="L286" title="All 2 branches missed.">        if (layerRatio.size() == 0) {</span>
<span class="nc" id="L287">            logger.info(&quot;Fail to get historical rating.&quot;);</span>
<span class="nc" id="L288">            return null;</span>
        } else {
<span class="nc bnc" id="L290" title="All 2 branches missed.">            for(int level = 0; level &lt;= totalLevels; level++) {</span>
<span class="nc" id="L291">                logger.debug(&quot;level {}: {}&quot;, level, StringUtils.join(layerRatio.get(level), &quot;,&quot;));</span>
<span class="nc" id="L292">                result.add(level, harmonicMean(layerRatio.get(level)));</span>
            }

<span class="nc" id="L295">            logger.info(&quot;Finally estimate ratio is {}&quot;, StringUtils.join(result, &quot;,&quot;));</span>

<span class="nc" id="L297">            return result;</span>
        }
    }

    private static void optimizeSizeMap(Map&lt;Long, Double&gt; sizeMap, CubeSegment cubeSegment) {
<span class="nc" id="L302">        CubeInstance cubeInstance = cubeSegment.getCubeInstance();</span>
<span class="nc" id="L303">        int totalLevels = cubeInstance.getCuboidScheduler().getBuildLevel();</span>
<span class="nc" id="L304">        List&lt;List&lt;Long&gt;&gt; layeredCuboids = cubeInstance.getCuboidScheduler().getCuboidsByLayer();</span>

<span class="nc" id="L306">        logger.info(&quot;cube size is {} before optimize&quot;, SumHelper.sumDouble(sizeMap.values()));</span>

<span class="nc" id="L308">        List&lt;Double&gt; levelRating = getHistoricalRating(cubeSegment, cubeInstance, totalLevels);</span>

<span class="nc bnc" id="L310" title="All 2 branches missed.">        if (levelRating == null) {</span>
<span class="nc" id="L311">            logger.info(&quot;Fail to optimize, use origin.&quot;);</span>
<span class="nc" id="L312">            return;</span>
        }

<span class="nc bnc" id="L315" title="All 2 branches missed.">        for (int level = 0; level &lt;= totalLevels; level++) {</span>
<span class="nc" id="L316">            Double rate = levelRating.get(level);</span>

<span class="nc bnc" id="L318" title="All 2 branches missed.">            for (Long cuboidId : layeredCuboids.get(level)) {</span>
<span class="nc bnc" id="L319" title="All 2 branches missed.">                double oriValue = (sizeMap.get(cuboidId) == null ? 0.0 : sizeMap.get(cuboidId));</span>
<span class="nc" id="L320">                sizeMap.put(cuboidId, oriValue * rate);</span>
<span class="nc" id="L321">            }</span>
        }

<span class="nc" id="L324">        logger.info(&quot;cube size is {} after optimize&quot;, SumHelper.sumDouble(sizeMap.values()));</span>

<span class="nc" id="L326">        return;</span>
    }


    /**
     * Estimate the cuboid's size
     *
     * @return the cuboid size in M bytes
     */
    private static double estimateCuboidStorageSize(CubeSegment cubeSegment, long cuboidId, long rowCount,
            long baseCuboidId, long baseCuboidCount, List&lt;Integer&gt; rowKeyColumnLength, long sourceRowCount) {

<span class="nc" id="L338">        int rowkeyLength = cubeSegment.getRowKeyPreambleSize();</span>
<span class="nc" id="L339">        KylinConfig kylinConf = cubeSegment.getConfig();</span>

<span class="nc" id="L341">        long mask = Long.highestOneBit(baseCuboidId);</span>
<span class="nc" id="L342">        long parentCuboidIdActualLength = (long) Long.SIZE - Long.numberOfLeadingZeros(baseCuboidId);</span>
<span class="nc bnc" id="L343" title="All 2 branches missed.">        for (int i = 0; i &lt; parentCuboidIdActualLength; i++) {</span>
<span class="nc bnc" id="L344" title="All 2 branches missed.">            if ((mask &amp; cuboidId) &gt; 0) {</span>
<span class="nc" id="L345">                rowkeyLength += rowKeyColumnLength.get(i); //colIO.getColumnLength(columnList.get(i));</span>
            }
<span class="nc" id="L347">            mask = mask &gt;&gt; 1;</span>
        }

        // add the measure length
<span class="nc" id="L351">        int normalSpace = rowkeyLength;</span>
<span class="nc" id="L352">        int countDistinctSpace = 0;</span>
<span class="nc" id="L353">        double percentileSpace = 0;</span>
<span class="nc" id="L354">        int topNSpace = 0;</span>
<span class="nc bnc" id="L355" title="All 2 branches missed.">        for (MeasureDesc measureDesc : cubeSegment.getCubeDesc().getMeasures()) {</span>
<span class="nc bnc" id="L356" title="All 2 branches missed.">            if (rowCount == 0)</span>
<span class="nc" id="L357">                break;</span>
<span class="nc" id="L358">            DataType returnType = measureDesc.getFunction().getReturnDataType();</span>
<span class="nc bnc" id="L359" title="All 2 branches missed.">            if (measureDesc.getFunction().getExpression().equals(FunctionDesc.FUNC_COUNT_DISTINCT)) {</span>
<span class="nc" id="L360">                long estimateDistinctCount = sourceRowCount / rowCount;</span>
<span class="nc bnc" id="L361" title="All 2 branches missed.">                estimateDistinctCount = estimateDistinctCount == 0 ? 1L : estimateDistinctCount;</span>
<span class="nc" id="L362">                countDistinctSpace += returnType.getStorageBytesEstimate(estimateDistinctCount);</span>
<span class="nc bnc" id="L363" title="All 2 branches missed.">            } else if (measureDesc.getFunction().getExpression().equals(FunctionDesc.FUNC_PERCENTILE)) {</span>
<span class="nc" id="L364">                percentileSpace += returnType.getStorageBytesEstimate(baseCuboidCount * 1.0 / rowCount);</span>
<span class="nc bnc" id="L365" title="All 2 branches missed.">            } else if (measureDesc.getFunction().getExpression().equals(TopNMeasureType.FUNC_TOP_N)) {</span>
<span class="nc" id="L366">                long estimateTopNCount = sourceRowCount / rowCount;</span>
<span class="nc bnc" id="L367" title="All 2 branches missed.">                estimateTopNCount = estimateTopNCount == 0 ? 1L : estimateTopNCount;</span>
<span class="nc" id="L368">                topNSpace += returnType.getStorageBytesEstimate(estimateTopNCount);</span>
<span class="nc" id="L369">            } else {</span>
<span class="nc" id="L370">                normalSpace += returnType.getStorageBytesEstimate();</span>
            }
<span class="nc" id="L372">        }</span>

<span class="nc" id="L374">        double cuboidSizeMemHungryRatio = kylinConf.getJobCuboidSizeCountDistinctRatio();</span>
<span class="nc" id="L375">        double cuboidSizeTopNRatio = kylinConf.getJobCuboidSizeTopNRatio();</span>

<span class="nc" id="L377">        double ret = (1.0 * normalSpace * rowCount</span>
                + 1.0 * countDistinctSpace * rowCount * cuboidSizeMemHungryRatio + 1.0 * percentileSpace * rowCount
                + 1.0 * topNSpace * rowCount * cuboidSizeTopNRatio) / (1024L * 1024L);
<span class="nc" id="L380">        return ret;</span>
    }

    private void print(PrintWriter out) {
<span class="nc" id="L384">        Map&lt;Long, Long&gt; cuboidRows = getCuboidRowEstimatesHLL();</span>
<span class="nc" id="L385">        Map&lt;Long, Double&gt; cuboidSizes = getCuboidSizeMap();</span>
<span class="nc" id="L386">        List&lt;Long&gt; cuboids = new ArrayList&lt;Long&gt;(cuboidRows.keySet());</span>
<span class="nc" id="L387">        Collections.sort(cuboids);</span>

<span class="nc" id="L389">        out.println(&quot;============================================================================&quot;);</span>
<span class="nc" id="L390">        out.println(&quot;Statistics of &quot; + seg);</span>
<span class="nc" id="L391">        out.println();</span>
<span class="nc" id="L392">        out.println(</span>
<span class="nc" id="L393">                &quot;Cube statistics hll precision: &quot; + cuboidRowEstimatesHLL.values().iterator().next().getPrecision());</span>
<span class="nc" id="L394">        out.println(&quot;Total cuboids: &quot; + cuboidRows.size());</span>
<span class="nc" id="L395">        out.println(&quot;Total estimated rows: &quot; + SumHelper.sumLong(cuboidRows.values()));</span>
<span class="nc" id="L396">        out.println(&quot;Total estimated size(MB): &quot; + SumHelper.sumDouble(cuboidSizes.values()));</span>
<span class="nc" id="L397">        out.println(&quot;Sampling percentage:  &quot; + samplingPercentage);</span>
<span class="nc" id="L398">        out.println(&quot;Mapper overlap ratio: &quot; + mapperOverlapRatioOfFirstBuild);</span>
<span class="nc" id="L399">        out.println(&quot;Mapper number: &quot; + mapperNumberOfFirstBuild);</span>
<span class="nc" id="L400">        printKVInfo(out);</span>
<span class="nc" id="L401">        printCuboidInfoTreeEntry(cuboidRows, cuboidSizes, out);</span>
<span class="nc" id="L402">        out.println(&quot;----------------------------------------------------------------------------&quot;);</span>
<span class="nc" id="L403">    }</span>

    //return MB
    public double estimateLayerSize(int level) {
<span class="nc bnc" id="L407" title="All 2 branches missed.">        if (cuboidScheduler == null) {</span>
<span class="nc" id="L408">            throw new UnsupportedOperationException(&quot;cuboid scheduler is null&quot;);</span>
        }
<span class="nc" id="L410">        List&lt;List&lt;Long&gt;&gt; layeredCuboids = cuboidScheduler.getCuboidsByLayer();</span>
<span class="nc" id="L411">        Map&lt;Long, Double&gt; cuboidSizeMap = getCuboidSizeMap();</span>
<span class="nc" id="L412">        double ret = 0;</span>
<span class="nc bnc" id="L413" title="All 2 branches missed.">        for (Long cuboidId : layeredCuboids.get(level)) {</span>
<span class="nc bnc" id="L414" title="All 2 branches missed.">            ret += cuboidSizeMap.get(cuboidId) == null ? 0.0 : cuboidSizeMap.get(cuboidId);</span>
<span class="nc" id="L415">        }</span>

<span class="nc" id="L417">        logger.info(&quot;Estimating size for layer {}, all cuboids are {}, total size is {}&quot;, level,</span>
<span class="nc" id="L418">                StringUtils.join(layeredCuboids.get(level), &quot;,&quot;), ret);</span>
<span class="nc" id="L419">        return ret;</span>
    }

    public List&lt;Long&gt; getCuboidsByLayer(int level) {
<span class="nc bnc" id="L423" title="All 2 branches missed.">        if (cuboidScheduler == null) {</span>
<span class="nc" id="L424">            throw new UnsupportedOperationException(&quot;cuboid scheduler is null&quot;);</span>
        }
<span class="nc" id="L426">        List&lt;List&lt;Long&gt;&gt; layeredCuboids = cuboidScheduler.getCuboidsByLayer();</span>
<span class="nc" id="L427">        return layeredCuboids.get(level);</span>
    }

    private void printCuboidInfoTreeEntry(Map&lt;Long, Long&gt; cuboidRows, Map&lt;Long, Double&gt; cuboidSizes, PrintWriter out) {
<span class="nc bnc" id="L431" title="All 2 branches missed.">        if (cuboidScheduler == null) {</span>
<span class="nc" id="L432">            throw new UnsupportedOperationException(&quot;cuboid scheduler is null&quot;);</span>
        }
<span class="nc" id="L434">        long baseCuboid = Cuboid.getBaseCuboidId(seg.getCubeDesc());</span>
<span class="nc" id="L435">        int dimensionCount = Long.bitCount(baseCuboid);</span>
<span class="nc" id="L436">        printCuboidInfoTree(-1L, baseCuboid, cuboidScheduler, cuboidRows, cuboidSizes, dimensionCount, 0, out);</span>
<span class="nc" id="L437">    }</span>

    private void printKVInfo(PrintWriter writer) {
<span class="nc" id="L440">        Cuboid cuboid = Cuboid.getBaseCuboid(seg.getCubeDesc());</span>
<span class="nc" id="L441">        RowKeyEncoder encoder = new RowKeyEncoder(seg, cuboid);</span>
<span class="nc bnc" id="L442" title="All 2 branches missed.">        for (TblColRef col : cuboid.getColumns()) {</span>
<span class="nc" id="L443">            writer.println(&quot;Length of dimension &quot; + col + &quot; is &quot; + encoder.getColumnLength(col));</span>
<span class="nc" id="L444">        }</span>
<span class="nc" id="L445">    }</span>

    private static void printCuboidInfoTree(long parent, long cuboidID, final CuboidScheduler scheduler,
            Map&lt;Long, Long&gt; cuboidRows, Map&lt;Long, Double&gt; cuboidSizes, int dimensionCount, int depth, PrintWriter out) {
<span class="nc" id="L449">        printOneCuboidInfo(parent, cuboidID, cuboidRows, cuboidSizes, dimensionCount, depth, out);</span>

<span class="nc" id="L451">        List&lt;Long&gt; children = scheduler.getSpanningCuboid(cuboidID);</span>
<span class="nc" id="L452">        Collections.sort(children);</span>

<span class="nc bnc" id="L454" title="All 2 branches missed.">        for (Long child : children) {</span>
<span class="nc" id="L455">            printCuboidInfoTree(cuboidID, child, scheduler, cuboidRows, cuboidSizes, dimensionCount, depth + 1, out);</span>
<span class="nc" id="L456">        }</span>
<span class="nc" id="L457">    }</span>

    private static void printOneCuboidInfo(long parent, long cuboidID, Map&lt;Long, Long&gt; cuboidRows,
            Map&lt;Long, Double&gt; cuboidSizes, int dimensionCount, int depth, PrintWriter out) {
<span class="nc" id="L461">        StringBuffer sb = new StringBuffer();</span>
<span class="nc bnc" id="L462" title="All 2 branches missed.">        for (int i = 0; i &lt; depth; i++) {</span>
<span class="nc" id="L463">            sb.append(&quot;    &quot;);</span>
        }
<span class="nc" id="L465">        String cuboidName = Cuboid.getDisplayName(cuboidID, dimensionCount);</span>
<span class="nc" id="L466">        sb.append(&quot;|---- Cuboid &quot;).append(cuboidName);</span>

<span class="nc" id="L468">        long rowCount = cuboidRows.get(cuboidID);</span>
<span class="nc" id="L469">        double size = cuboidSizes.get(cuboidID);</span>
<span class="nc" id="L470">        sb.append(&quot;, est row: &quot;).append(rowCount).append(&quot;, est MB: &quot;).append(formatDouble(size));</span>

<span class="nc bnc" id="L472" title="All 2 branches missed.">        if (parent != -1) {</span>
<span class="nc" id="L473">            sb.append(&quot;, shrink: &quot;).append(formatDouble(100.0 * cuboidRows.get(cuboidID) / cuboidRows.get(parent)))</span>
<span class="nc" id="L474">                    .append(&quot;%&quot;);</span>
        }

<span class="nc" id="L477">        out.println(sb.toString());</span>
<span class="nc" id="L478">    }</span>

    private static String formatDouble(double input) {
<span class="nc" id="L481">        return new DecimalFormat(&quot;#.##&quot;, DecimalFormatSymbols.getInstance(Locale.ROOT)).format(input);</span>
    }

    public static class CubeStatsResult {
<span class="nc" id="L485">        private int percentage = 100;</span>
<span class="nc" id="L486">        private double mapperOverlapRatio = 0;</span>
<span class="nc" id="L487">        private long sourceRecordCount = 0;</span>
<span class="nc" id="L488">        private int mapperNumber = 0;</span>
<span class="nc" id="L489">        private Map&lt;Long, HLLCounter&gt; counterMap = Maps.newHashMap();</span>

<span class="nc" id="L491">        public CubeStatsResult(Path path, int precision) throws IOException {</span>
<span class="nc" id="L492">            Configuration hadoopConf = HadoopUtil.getCurrentConfiguration();</span>
<span class="nc" id="L493">            Option seqInput = SequenceFile.Reader.file(path);</span>
<span class="nc" id="L494">            try (Reader reader = new SequenceFile.Reader(hadoopConf, seqInput)) {</span>
<span class="nc" id="L495">                LongWritable key = (LongWritable) ReflectionUtils.newInstance(reader.getKeyClass(), hadoopConf);</span>
<span class="nc" id="L496">                BytesWritable value = (BytesWritable) ReflectionUtils.newInstance(reader.getValueClass(), hadoopConf);</span>
<span class="nc bnc" id="L497" title="All 2 branches missed.">                while (reader.next(key, value)) {</span>
<span class="nc bnc" id="L498" title="All 2 branches missed.">                    if (key.get() == 0L) {</span>
<span class="nc" id="L499">                        percentage = Bytes.toInt(value.getBytes());</span>
<span class="nc bnc" id="L500" title="All 2 branches missed.">                    } else if (key.get() == -1) {</span>
<span class="nc" id="L501">                        mapperOverlapRatio = Bytes.toDouble(value.getBytes());</span>
<span class="nc bnc" id="L502" title="All 2 branches missed.">                    } else if (key.get() == -2) {</span>
<span class="nc" id="L503">                        mapperNumber = Bytes.toInt(value.getBytes());</span>
<span class="nc bnc" id="L504" title="All 2 branches missed.">                    } else if (key.get() == -3) {</span>
<span class="nc" id="L505">                        sourceRecordCount = Bytes.toLong(value.getBytes());</span>
<span class="nc bnc" id="L506" title="All 2 branches missed.">                    } else if (key.get() &gt; 0) {</span>
<span class="nc" id="L507">                        HLLCounter hll = new HLLCounter(precision);</span>
<span class="nc" id="L508">                        ByteArray byteArray = new ByteArray(value.getBytes());</span>
<span class="nc" id="L509">                        hll.readRegisters(byteArray.asBuffer());</span>
<span class="nc" id="L510">                        counterMap.put(key.get(), hll);</span>
<span class="nc" id="L511">                    }</span>
                }
            }
<span class="nc" id="L514">        }</span>

        public int getPercentage() {
<span class="nc" id="L517">            return percentage;</span>
        }

        public double getMapperOverlapRatio() {
<span class="nc" id="L521">            return mapperOverlapRatio;</span>
        }

        public int getMapperNumber() {
<span class="nc" id="L525">            return mapperNumber;</span>
        }

        public Map&lt;Long, HLLCounter&gt; getCounterMap() {
<span class="nc" id="L529">            return Collections.unmodifiableMap(counterMap);</span>
        }

        public long getSourceRecordCount() {
<span class="nc" id="L533">            return sourceRecordCount;</span>
        }
    }

    public static void main(String[] args) throws IOException {
<span class="nc" id="L538">        System.out.println(&quot;CubeStatsReader is used to read cube statistic saved in metadata store&quot;);</span>
<span class="nc" id="L539">        KylinConfig config = KylinConfig.getInstanceFromEnv();</span>
<span class="nc" id="L540">        CubeInstance cube = CubeManager.getInstance(config).getCube(args[0]);</span>
<span class="nc" id="L541">        List&lt;CubeSegment&gt; segments = cube.getSegments();</span>

<span class="nc" id="L543">        PrintWriter out = new PrintWriter(</span>
                new BufferedWriter(new OutputStreamWriter(System.out, StandardCharsets.UTF_8)));
<span class="nc bnc" id="L545" title="All 2 branches missed.">        for (CubeSegment seg : segments) {</span>
            try {
<span class="nc" id="L547">                new CubeStatsReader(seg, config).print(out);</span>
<span class="nc" id="L548">            } catch (Exception e) {</span>
<span class="nc" id="L549">                logger.info(&quot;CubeStatsReader for Segment {} failed, skip it.&quot;, seg.getName());</span>
<span class="nc" id="L550">            }</span>
<span class="nc" id="L551">        }</span>
<span class="nc" id="L552">        out.flush();</span>
<span class="nc" id="L553">    }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>